#!/usr/bin/env python3

# modules
import pandas as pd
import sys
import argparse as ap
from time import asctime as at
import os


if len(sys.argv) <= 1:
	sys.argv.append("-h")

if sys.argv[1] in ["-h", "--help", "getopt", "usage", "-help", "help"]:
	sys.exit('''

	--------------------------------------------------------------------------------
	all2vcf stats
	--------------------------------------------------------------------------------

	USAGE:  all2vcf stats [ options ]

	Obtain statistics on the provided VCF files.

	OPTIONS:

	--vcf               Input VCF files to compute statistics on		[mandatory]
	--vcf-names         Names of the input VCF files, IN THE SAME ORDER	[mandatory]
	--gff				GFF file to extract "gene" annotations from.	[off]
						A file will be created for each annotation
						feature (e.g. "gene", "exon", ...)
	--exclude-chrom     SPACE-separated list of seq to be excluded		[off]
	--basename          Prefix for output file(s)				[all2vcf.stats]
	--output-dir        Output directory (created if non-existent)		[current]

	''')


# parser
p = ap.ArgumentParser()
p.add_argument("--vcf", nargs="+", required=True)
p.add_argument("--vcf-names", nargs="+", required=True)
p.add_argument("--gff")
p.add_argument("--exclude-chrom", nargs="*")
p.add_argument("--basename", type=str, default="all2vcf.stats")
p.add_argument("--output-dir", default=".")
args = p.parse_args()


# workspace
os.makedirs(args.output_dir + "/by_chrom", exist_ok=True)
os.makedirs(args.output_dir + "/by_input_file", exist_ok=True)
if args.gff:
	os.makedirs(args.output_dir + "/gff/by_chrom" , exist_ok=True)
	os.makedirs(args.output_dir + "/gff/by_input_file" , exist_ok=True)


# functions
# define function to convert a "=" separated list
# to a dictionary
def convert_to_dictionary(lst):
	# add indels if found
	if "INDEL" in lst:
		lst.append("VAR_TYPE=INDEL")
		lst = [ x for x in lst if x != "INDEL" ]
	# convert sv type with var type
	lst = [ x.replace("SVTYPE", "VAR_TYPE") for x in lst ]
	# split by equal sign
	dict = [ x.split("=") for x in lst ]
	# transform into a dictionary
	dict = { x[0]:x[1] for x in dict }
	# if no "VAR_TYPE" is found: it's a SNP
	if "VAR_TYPE" not in dict.keys():
		dict["VAR_TYPE"] = "SNP"
	#
	return dict

# get variant stats within features in gff file
def get_feature_stats(stats, gff_input):
	# extract all available features
	# extract all tuples for each feature composed of (chrom, start, end)
	# intersect variants with these positions
	# retain only those that are found within
	# create a feature_stat_file
	# append (feat, feature_stat_file) tuple to feature_stats
	# and return it
	Feature_stats = []
	gff = pd.read_csv(gff_input, comment="#", sep="\t", header=None)
	Features = list(set(gff.iloc[:,2].tolist()))
	# iterate over the features
	for feat in Features:
		# extract coordinates of feature in each chromosome
		Coords_list = [ tuple(tup)[1:] for tup in gff[gff.iloc[:,2]==feat].iloc[:,[0,3,4]].itertuples() ]
		Coords = {}
		for tup in Coords_list:
			try:
				Coords[tup[0]].append((int(tup[1]), int(tup[2])))
			except KeyError:
				Coords[tup[0]] = [(int(tup[1]), int(tup[2]))]
		#
		Kept_variants = []
		for tup in stats.itertuples():
			line = tuple(tup)
			# item 0 is the index
			# so we must take 1 and 2
			chrom = str(line[1])
			pos = int(line[2])
			k = 0
			# assess if contained within feature
			for feat_range in Coords[chrom]:
				if feat_range[0] <= pos <= feat_range[1]:
					# if so: append to main list
					Kept_variants.append(line[1:])
					break
		# convert main list to dataframe
		feature_stat_df = pd.DataFrame(Kept_variants)
		feature_stat_df.columns = ["CHROM", "POS", "VAR_TYPE", "REF", "ALT"]
		Feature_stats.append((feat, feature_stat_df))
	# return final list of df
	return Feature_stats


# empty list of results
Results = []
Results_chrom = []
if args.gff:
	Feat_results = {}
	Feat_results_chrom = {}


# main code
for input_file in args.vcf:

	# get vcf name
	vcf_name = args.vcf_names[args.vcf.index(input_file)]

	# initial message
	sys.stderr.write(f"\n[{at()}] ### Working on {input_file} ### \n\n")

	# read header
	INPUT = open(input_file, "r")
	Header = [ line for line in INPUT if line[0] == "#" ]
	INPUT.close()

	# read input file
	df = pd.read_csv(input_file, sep="\t", header=None, usecols=range(0,8), comment="#")
	df.columns = ["CHROM","POS","ID","REF","ALT","QUAL","FILTER","INFO"]

	# remove scaffolds that the user wants to exclude
	if args.exclude_chrom:
		sys.stderr.write(f"[{at()}] Excluding {len(args.exclude_chrom)} sequences from --exclude-chrom ... ")
		#
		if len(args.exclude_chrom) > 0:
			#
			# remove lines from VCF file
			# the pattern defines an OR condition with all the scaffolds to exclude
			# the "contains" statement checks if the pattern is contained in the row
			# the "~" sign inverts the boolean values (i.e. from True to False, and viceversa)
			# the mask is then used to subset the dataframe
			pattern = "|".join(args.exclude_chrom)
			mask = df["CHROM"].str.contains(pattern)
			excluded = df.loc[mask , :]
			df = df.loc[~mask , :]
			#
			if len(Header) > 0:
				# remove lines from header
				# this command retains a line from the original header ...
				# ... only if it does not contain any of the scaffolds to be excluded
				# that means
				# only if all the scaffolds to be excluded are NOT contained in it
				Header = [ line for line in Header if all([ seqname in line for seqname in args.exclude_chrom ]) == False ]

			# writing to output a file with excluded variantsprint(
			outfile = args.output_dir + "/" + args.basename + ".excluded.tsv"
			excluded.to_csv(outfile, sep="\t", header=True, index=False)
			sys.stderr.write("DONE\n")
			sys.stderr.write(f"[{at()}] Excluded {sum(mask)} variants from the scaffolds declared in --exclude-chrom\n")
			sys.stderr.write(f"[{at()}] These variants have been written to {outfile}\n")
	#
	# add indels if not properly labelled
	# first mask selects variant rows where length of ref allele is != length of alt allele -> candidate indel
	# second mask selects only rows where the INFO field does NOT contain the word "SVTYPE" (which would be structural variant)
	# third mask selects only rows where the INFO field does NOT contain the word "INDEL" already
	# if all three masks ar true: the word "INDEL" is prepended to the INFO field as per the VCF 4.2 standard format
	mask1 = df.REF.str.len() != df.ALT.str.len()
	mask2 = ~df.INFO.str.contains("SVTYPE")
	mask3 = ~df.INFO.str.contains("INDEL")
	num_indels = df.loc[mask1 & mask2 & mask3, "INFO"].shape[0]
	sys.stderr.write(f"[{at()}] Found {num_indels} candidate indels that where the annotation did not comply the VCF standard\n")
	df.loc[mask1 & mask2 & mask3, "INFO"] = "INDEL;" + df.loc[mask1 & mask2 & mask3, "INFO"]
	sys.stderr.write(f"[{at()}] The annotation was fixed for these {num_indels} indels\n")

	# extract relevant fields
	# which are chromosome, position, id, and a few info (SV length and type)
	sys.stderr.write(f"[{at()}] Extracting information on the retained variants ... ")
	stats = df.copy()
	stats["INFO"] = stats["INFO"].str.split(";").apply(lambda x:convert_to_dictionary(x))
	stats["VAR_TYPE"] = stats["INFO"].str["VAR_TYPE"]
	stats = stats.loc[: , ["CHROM", "POS", "VAR_TYPE", "REF", "ALT"]]
	sys.stderr.write("DONE\n")
	sys.stderr.write(f"[{at()}] Extracted info on {stats.shape[0]} variants \n")

	# write to output this table
	outfile = args.output_dir + "/by_input_file/" + args.basename + "." + vcf_name + ".info.tsv"
	stats.to_csv(outfile, sep="\t", header=True, index=False)

	# if the user specified a GFF / GFF3 file
	# then extract those within features
	# and write to output
	if args.gff:
		sys.stderr.write(f"[{at()}] Extracting variants contained in GFF features ... ")
		Feature_stats = get_feature_stats(stats, args.gff)
		for tup in Feature_stats:
			feat = tup[0]
			feature_df = tup[1]
			outfile = args.output_dir + "/gff/by_input_file/" + args.basename + "." + vcf_name + "." + feat + ".info.tsv"
			feature_df.to_csv(outfile, sep="\t", header=True, index=False)
		#
		sys.stderr.write("DONE\n")

	# create summary
	s = stats.groupby("VAR_TYPE").count()["CHROM"]
	s = s.rename(vcf_name)
	s_chrom = stats.groupby(["CHROM", "VAR_TYPE"]).count()["POS"]
	s_chrom = s_chrom.rename(vcf_name)
	Results.append(s)
	Results_chrom.append(s_chrom)

	# create stats by feature if requested
	if args.gff:
		for tup in Feature_stats:
			feat = tup[0]
			stats_df = tup[1]
			# create summary
			feat_s = stats_df.groupby("VAR_TYPE").count()["CHROM"]
			feat_s = feat_s.rename(vcf_name + "_" + feat)
			feat_s_chrom = stats_df.groupby(["CHROM", "VAR_TYPE"]).count()["POS"]
			feat_s_chrom = feat_s_chrom.rename(vcf_name + "_" + feat)
			try:
				Feat_results[feat].append(feat_s)
				Feat_results_chrom[feat].append(feat_s_chrom)
			except KeyError:
				Feat_results[feat] = [feat_s]
				Feat_results_chrom[feat] = [feat_s_chrom]


# process results
df = pd.concat(Results, join="outer", axis=1)
df = df.fillna(0)
df = df.astype(int)

# write to output
outfile = args.output_dir + "/" + args.basename + ".summary.tsv"
df = df.reset_index()
df.to_csv(outfile, sep="\t", header=True, index=False)

# process results by chromosome
df_chrom = pd.concat(Results_chrom, join="outer", axis=1)
df_chrom = df_chrom.fillna(0)
df_chrom = df_chrom.astype(int)

# write to output
outfile = args.output_dir + "/by_chrom/" + args.basename + ".summary.by_chrom.tsv"
df_chrom = df_chrom.reset_index()
df_chrom.to_csv(outfile, sep="\t", header=True, index=False)

# if args gff, write those to output too
if args.gff:
	for feat in Feat_results.keys():
		# process results
		df = pd.concat(Feat_results[feat], join="outer", axis=1)
		df = df.fillna(0)
		df = df.astype(int)
		# write to output
		outfile = args.output_dir + "/" + "gff" + "/" + args.basename + "." + feat + ".summary.tsv"
		df = df.reset_index()
		df.to_csv(outfile, sep="\t", header=True, index=False)

	for feat in Feat_results_chrom.keys():
		# process results by chromosome
		df_chrom = pd.concat(Feat_results_chrom[feat], join="outer", axis=1)
		df_chrom = df_chrom.fillna(0)
		df_chrom = df_chrom.astype(int)
		# write to output
		outfile = args.output_dir + "/gff/by_chrom/" + args.basename + "." + feat + ".summary.by_chrom.tsv"
		df_chrom = df_chrom.reset_index()
		df_chrom.to_csv(outfile, sep="\t", header=True, index=False)
