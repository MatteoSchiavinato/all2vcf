#!/usr/bin/env python3

# modules
import pandas as pd
import sys
import argparse as ap
from time import asctime as at
import os


if len(sys.argv) <= 1:
	sys.argv.append("-h")

if sys.argv[1] in ["-h", "--help", "getopt", "usage", "-help", "help"]:
	sys.exit('''

	--------------------------------------------------------------------------------
	all2vcf stats
	--------------------------------------------------------------------------------

	USAGE:  all2vcf stats [ options ]

	Obtain statistics on the provided VCF files.

	OPTIONS:

	--vcf               Input VCF files to compute statistics on		[mandatory]
	--vcf-names         Names of the input VCF files, IN THE SAME ORDER	[mandatory]
	--exclude-chrom     SPACE-separated list of seq to be excluded		[off]
	--basename          Prefix for output file(s)				[all2vcf.stats]
	--output-dir        Output directory (created if non-existent)		[current]

	''')


# parser
p = ap.ArgumentParser()
p.add_argument("--vcf", nargs="+", required=True)
p.add_argument("--vcf-names", nargs="+", required=True)
p.add_argument("--exclude-chrom", nargs="*")
p.add_argument("--basename", type=str, default="all2vcf.stats")
p.add_argument("--output-dir", default=".")
args = p.parse_args()


# workspace
os.makedirs(args.output_dir, exist_ok=True)

# functions
# define function to convert a "=" separated list
# to a dictionary
def convert_to_dictionary(lst):
	# add indels if found
	if "INDEL" in lst:
		lst.append("VAR_TYPE=INDEL")
		lst = [ x for x in lst if x != "INDEL" ]
	# convert sv type with var type
	lst = [ x.replace("SVTYPE", "VAR_TYPE") for x in lst ]
	# split by equal sign
	dict = [ x.split("=") for x in lst ]
	# transform into a dictionary
	dict = { x[0]:x[1] for x in dict }
	# if no "VAR_TYPE" is found: it's a SNP
	if "VAR_TYPE" not in dict.keys():
		dict["VAR_TYPE"] = "SNP"
	#
	return dict

# empty list of results
Results = []
Results_chrom = []

# main code
for input_file in args.vcf:

	# get vcf name
	vcf_name = args.vcf_names[args.vcf.index(input_file)]

	# initial message
	sys.stderr.write(f"\n[{at()}] ### Working on {input_file} ### \n\n")

	# read header
	INPUT = open(input_file, "r")
	Header = [ line for line in INPUT if line[0] == "#" ]
	INPUT.close()

	# read input file
	df = pd.read_csv(input_file, sep="\t", header=None, usecols=range(0,8), comment="#")
	df.columns = ["CHROM","POS","ID","REF","ALT","QUAL","FILTER","INFO"]

	# remove scaffolds that the user wants to exclude
	if args.exclude_chrom:
		sys.stderr.write(f"[{at()}] Excluding {len(args.exclude_chrom)} sequences from --exclude-chrom ... ")
		#
		if len(args.exclude_chrom) > 0:
			#
			# remove lines from VCF file
			# the pattern defines an OR condition with all the scaffolds to exclude
			# the "contains" statement checks if the pattern is contained in the row
			# the "~" sign inverts the boolean values (i.e. from True to False, and viceversa)
			# the mask is then used to subset the dataframe
			pattern = "|".join(args.exclude_chrom)
			mask = df["CHROM"].str.contains(pattern)
			excluded = df.loc[mask , :]
			df = df.loc[~mask , :]
			#
			if len(Header) > 0:
				# remove lines from header
				# this command retains a line from the original header ...
				# ... only if it does not contain any of the scaffolds to be excluded
				# that means
				# only if all the scaffolds to be excluded are NOT contained in it
				Header = [ line for line in Header if all([ seqname in line for seqname in args.exclude_chrom ]) == False ]

			# writing to output a file with excluded variantsprint(
			outfile = args.output_dir + "/" + args.basename + ".excluded.tsv"
			excluded.to_csv(outfile, sep="\t", header=True, index=False)
			sys.stderr.write("DONE\n")
			sys.stderr.write(f"[{at()}] Excluded {sum(mask)} variants from the scaffolds declared in --exclude-chrom\n")
			sys.stderr.write(f"[{at()}] These variants have been written to {outfile}\n")
			#
	#
	# add indels if not properly labelled
	# first mask selects variant rows where length of ref allele is != length of alt allele -> candidate indel
	# second mask selects only rows where the INFO field does NOT contain the word "SVTYPE" (which would be structural variant)
	# third mask selects only rows where the INFO field does NOT contain the word "INDEL" already
	# if all three masks ar true: the word "INDEL" is prepended to the INFO field as per the VCF 4.2 standard format
	mask1 = df.REF.str.len() != df.ALT.str.len()
	mask2 = ~df.INFO.str.contains("SVTYPE")
	mask3 = ~df.INFO.str.contains("INDEL")
	num_indels = df.loc[mask1 & mask2 & mask3, "INFO"].shape[0]
	sys.stderr.write(f"[{at()}] Found {num_indels} candidate indels that where the annotation did not comply the VCF standard\n")
	df.loc[mask1 & mask2 & mask3, "INFO"] = "INDEL;" + df.loc[mask1 & mask2 & mask3, "INFO"]
	sys.stderr.write(f"[{at()}] The annotation was fixed for these {num_indels} indels\n")

	# extract relevant fields
	# which are chromosome, position, id, and a few info (SV length and type)
	sys.stderr.write(f"[{at()}] Extracting information on the retained variants ... ")
	stats = df.copy()
	stats["INFO"] = stats["INFO"].str.split(";").apply(lambda x:convert_to_dictionary(x))
	stats["VAR_TYPE"] = stats["INFO"].str["VAR_TYPE"]
	stats = stats.loc[: , ["CHROM", "POS", "VAR_TYPE", "REF", "ALT"]]
	sys.stderr.write("DONE\n")
	sys.stderr.write(f"[{at()}] Extracted info on {stats.shape[0]} variants \n")

	# write to output this table
	outfile = args.output_dir + "/" + args.basename + "." + vcf_name + ".info.tsv"
	stats.to_csv(outfile, sep="\t", header=True, index=False)

	# create summary
	s = stats.groupby("VAR_TYPE").count()["CHROM"]
	s = s.rename(vcf_name)
	s_chrom = stats.groupby(["CHROM", "VAR_TYPE"]).count()["POS"]
	s_chrom = s_chrom.rename(vcf_name)
	Results.append(s)
	Results_chrom.append(s_chrom)

# process results
df = pd.concat(Results, join="outer", axis=1)
df = df.fillna(0)
df = df.astype(int)

# write to output
outfile = args.output_dir + "/" + args.basename + ".summary.tsv"
df = df.reset_index()
df.to_csv(outfile, sep="\t", header=True, index=False)

# process results by chromosome
df_chrom = pd.concat(Results_chrom, join="outer", axis=1)
df_chrom = df_chrom.fillna(0)
df_chrom = df_chrom.astype(int)

# write to output
outfile = args.output_dir + "/" + args.basename + ".summary.by_chrom.tsv"
df_chrom = df_chrom.reset_index()
df_chrom.to_csv(outfile, sep="\t", header=True, index=False)
